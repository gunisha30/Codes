{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of audio2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunisha30/codes/blob/master/Copy_of_audio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcHI-srP2mQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install praat-parselmouth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nw_Eah9-zzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bfe84214-9c20-4105-e4ad-f0c4af5aa085"
      },
      "source": [
        "import moviepy.editor as mp\n",
        "clip = mp.VideoFileClip('/content/drive/My Drive/awarathon/videos/sovitq3.mp4')\n",
        "duration = math.floor(clip.duration)\n",
        "image_time_interval = 2\n",
        "print(duration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lk3QLlDkZMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pitch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StxDerUCki0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pitch\n",
        "\n",
        "p = pitch.find_pitch('/content/drive/My Drive/awarathon/George.wav')\n",
        "\n",
        "print('pitch =', p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2DH-8Qf0yq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!sudo apt-get install ffmpeg libav-tools\n",
        "!sudo pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzl-kVqI-h4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa as l\n",
        "import os\n",
        "import numpy as np\n",
        "os.chdir('/content/drive/My Drive/awarathon')\n",
        "arr,sr=l.load('George.wav')\n",
        "arr.size#/sr #length\n",
        "#print(sr)\n",
        "2871072/22050\n",
        "u=22049*5\n",
        "l=u-22049\n",
        "arrnew=arr[l:u+1]\n",
        "np.sum(arrnew)/22050"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tMVcQY_8nhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert mp4 to wav \n",
        "import sys\n",
        "import os\n",
        "from moviepy.editor import *\n",
        "\n",
        "# name is the path, if its in the root directory then its just the video name\n",
        "def convert_to_audio(name):\n",
        "  video = VideoFileClip(name)\n",
        "  audio = video.audio\n",
        "  audio.write_audiofile('snigdhaq3.wav')\n",
        "\n",
        "#folder renaming: first-Nishkarsh second-Yash third-Vishesh\n",
        "\n",
        "#os.chdir('/content/drive/My Drive/awarathon/videos')\n",
        "name=\"snigdhaq3.mp4\"\n",
        "convert_to_audio(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yXBK0q-V85U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "6da133c1-3ac6-4522-d1b2-1fae33f3de4d"
      },
      "source": [
        "import parselmouth\n",
        "from parselmouth.praat import call, run_file\n",
        "import inspect as i\n",
        "import sys\n",
        "import scipy.io.wavfile\n",
        "import math\n",
        "import moviepy.editor as mp\n",
        "\n",
        "def mysppaus(m,p,l):              #pause rate and articulation rate\n",
        "    sound=p+\"/\"+m+\".wav\"          #entire path till audio file\n",
        "    sourcerun=\"/content/drive/My Drive/awarathon/myspsolution.praat\"                  #path till mysolution.praat\n",
        "    path=p                        #path till the folder which has audio file\n",
        "    try:\n",
        "        objects= run_file(sourcerun, -20, 2, 1, \"yes\",sound,path, 80, 400, 0.01, capture_output=True) \n",
        "        z1=str(objects[1])\n",
        "        z2=z1.strip().split()\n",
        "        print(z2)\n",
        "        print (\"articulation rate=\",z2[3])\n",
        "        p=int(z2[1])                          #pause length in secs\n",
        "        print(p)                            \n",
        "        a=p/l                                 #ratio of pause length and total length\n",
        "        print(\"rate of pause=\",a)\n",
        "        print (\"pause percentage=\",a*100)\n",
        "    except:\n",
        "        print (\"Try again the sound of the audio was not clear\")\n",
        "    return;\n",
        "\n",
        "\n",
        "audioname=\"Q2converted\"\n",
        "path1=\"/content/drive/My Drive/awarathon/first\"\n",
        "#path1='/content'\n",
        "#length of video files \n",
        "\n",
        "clip = mp.VideoFileClip('/content/drive/My Drive/awarathon/first/Q2.mp4')\n",
        "duration = math.floor(clip.duration) #in seconds\n",
        "image_time_interval = 2\n",
        "print('duration=',duration)\n",
        "mysppaus(audioname,path1,duration)\n",
        "#mysppaus(audioname,path1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "duration= 30\n",
            "['96', '2', '3', '4', '25.1', '30', '0.8', '179.54', '42.03', '168.5', '73', '348', '158', '182', '0.85']\n",
            "articulation rate= 4\n",
            "2\n",
            "rate of pause= 0.06666666666666667\n",
            "pause percentage= 6.666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t00qI09Qd-JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install aubio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CEJOCdx8DEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io.wavfile\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/awarathon')\n",
        "rate, arr = scipy.io.wavfile.read(\"George.wav\")\n",
        "print(arr.shape[0])\n",
        "print(arr.size)\n",
        "length=arr.shape[0]/rate\n",
        "print(length/60)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_k5DZ4UP1zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZyXt5AFK5pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import youtube_dl\n",
        "\n",
        "def download_from_vimeo(vid_link):\n",
        "    ydl = youtube_dl.YoutubeDL({'outtmpl':'vid.mp4'})\n",
        "\n",
        "    with ydl:\n",
        "        result = ydl.extract_info(\n",
        "            vid_link,\n",
        "            download=True # We just want to extract the info\n",
        "        )\n",
        "\n",
        "    if 'entries' in result:\n",
        "        # Can be a playlist or a list of videos\n",
        "        video = result['entries'][0]\n",
        "    else:\n",
        "        # Just a video\n",
        "        video = result\n",
        "\n",
        "    print(video)\n",
        "\n",
        "download_from_vimeo('https://player.vimeo.com/video/348632880')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEBYQNQtfxMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "f=200\n",
        "p=69+(12*(math.log(f/440,2)))\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rBJl-6tmS0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#cap is a video capture object \n",
        "\n",
        "cap = cv2.VideoCapture(\"//content//drive//My Drive//awarathon//videos//gargiq2.mp4\")\n",
        "# rate, frame = cap.read()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    cv2_imshow(frame)\n",
        "    key=cv2.waitKey(0)\n",
        "    if (key==27):\n",
        "      break\n",
        "#     #if ret is False:\n",
        "#      #   break\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# roi = frame[269: 795, 537: 1416]\n",
        "# rows, cols, _ = roi.shape\n",
        "# gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "# gray_roi = cv2.GaussianBlur(gray_roi, (7, 7), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK6Y1zQO1mY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gaze_tracking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1BrCkgGZ0L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f620dd98-4135-4fdd-98f3-dd59f4b07c3e"
      },
      "source": [
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/eyecontact')\n",
        "\n",
        "from gaze_tracking import GazeTracking\n",
        "\n",
        "gaze = GazeTracking() \n",
        "input_stream = '/content/drive/My Drive/awarathon/videos/sovitq3.mp4'\n",
        "cap = cv2.VideoCapture(input_stream) #cap is a video capture object. \n",
        "cap.open(input_stream) \n",
        "width = int(cap.get(3)) #this returns the height and width of frames in this video\n",
        "height = int(cap.get(4))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') #fourcc is videowriter object, XVID is a 4 byte code (FourCC code)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) \n",
        "#fps = int(fps)\n",
        "#out = cv2.VideoWriter('/content/drive/My Drive/awarathon/eyeoutput/darshanq6out.avi', fourcc, fps, (width,height)) #videowriter is used to process and save videos. video is saved in out.avi file\n",
        "count = 0\n",
        "vc = 0\n",
        "res = []\n",
        "while cap.isOpened():  #returns true if video capturing/accessing is successful \n",
        "    # We get a new frame from the inout\n",
        "    flag, frame = cap.read()\n",
        "    if not flag:\n",
        "        break\n",
        "\n",
        "    # We send this frame to GazeTracking to analyze it\n",
        "    gaze.refresh(frame)\n",
        "\n",
        "    frame = gaze.annotated_frame()\n",
        "    text = \"\"\n",
        "    num = -1\n",
        "\n",
        "    if gaze.is_blinking():\n",
        "        text = \"Blinking\"\n",
        "        num = 0\n",
        "    elif gaze.is_right():\n",
        "        text = \"Looking right\"\n",
        "        num = 2\n",
        "    elif gaze.is_left():\n",
        "        text = \"Looking left\"\n",
        "        num = 3\n",
        "    elif gaze.is_center():\n",
        "        text = \"Looking center\"\n",
        "        num = 1\n",
        "\n",
        "    if num >= 0:\n",
        "        res.append(num)\n",
        "\n",
        "\n",
        "    #cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2) #used to write text on image \n",
        "\n",
        "    left_pupil = gaze.pupil_left_coords()\n",
        "    right_pupil = gaze.pupil_right_coords()\n",
        "    cv2.putText(frame, \"Left pupil:  \" + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
        "    cv2.putText(frame, \"Right pupil: \" + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
        "\n",
        "    #out.write(frame)\n",
        "    count += fps #count the total no of frames\n",
        "    #cap.set(1, count) \n",
        "    vc += 1\n",
        "\n",
        "    if cv2.waitKey(1) == 27:\n",
        "        break\n",
        "\n",
        "# from scipy import stats\n",
        "#\n",
        "# res = np.array(res)\n",
        "# print(stats.describe(res))\n",
        "# print(res)\n",
        "from collections import Counter\n",
        "dict = Counter(res)\n",
        "print(dict)\n",
        "print(sum(res)/len(res)) #get an average of all values(directions) in the res list \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 500, 1: 117})\n",
            "0.18962722852512157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4KqNVValppv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pnC76KBTlu8x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e9ea4559-e46d-41fc-acea-d984dcb1e99e"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/eyecontact')\n",
        "\n",
        "from gaze_tracking import GazeTracking\n",
        "\n",
        "f=glob.glob(\"/content/drive/My Drive/awarathon/tryauto/*.mp4\")\n",
        "for file in f:\n",
        "  gaze = GazeTracking() \n",
        "  input_stream = file\n",
        "  cap = cv2.VideoCapture(input_stream) #cap is a video capture object. \n",
        "  cap.open(input_stream) \n",
        "  width = int(cap.get(3)) #this returns the height and width of frames in this video\n",
        "  height = int(cap.get(4))\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID') #fourcc is videowriter object, XVID is a 4 byte code (FourCC code)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS) \n",
        "  #fps = int(fps)\n",
        "  #out = cv2.VideoWriter('/content/drive/My Drive/awarathon/eyeoutput/darshanq6out.avi', fourcc, fps, (width,height)) #videowriter is used to process and save videos. video is saved in out.avi file\n",
        "  count = 0\n",
        "  vc = 0\n",
        "  res = []\n",
        "  while cap.isOpened():  #returns true if video capturing/accessing is successful \n",
        "      # We get a new frame from the inout\n",
        "      flag, frame = cap.read()\n",
        "      if not flag:\n",
        "          break\n",
        "\n",
        "      # We send this frame to GazeTracking to analyze it\n",
        "      gaze.refresh(frame)\n",
        "\n",
        "      frame = gaze.annotated_frame()\n",
        "      text = \"\"\n",
        "      num = -1\n",
        "\n",
        "      if gaze.is_blinking():\n",
        "          text = \"Blinking\"\n",
        "          num = 0\n",
        "      elif gaze.is_right():\n",
        "          text = \"Looking right\"\n",
        "          num = 2\n",
        "      elif gaze.is_left():\n",
        "          text = \"Looking left\"\n",
        "          num = 3\n",
        "      elif gaze.is_center():\n",
        "          text = \"Looking center\"\n",
        "          num = 1\n",
        "\n",
        "      if num >= 0:\n",
        "          res.append(num)\n",
        "\n",
        "\n",
        "      #cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2) #used to write text on image \n",
        "\n",
        "      left_pupil = gaze.pupil_left_coords()\n",
        "      right_pupil = gaze.pupil_right_coords()\n",
        "      cv2.putText(frame, \"Left pupil:  \" + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
        "      cv2.putText(frame, \"Right pupil: \" + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
        "\n",
        "      #out.write(frame)\n",
        "      count += fps #count the total no of frames\n",
        "      #cap.set(1, count) \n",
        "      vc += 1\n",
        "\n",
        "      if cv2.waitKey(1) == 27:\n",
        "          break\n",
        "\n",
        "  from collections import Counter\n",
        "  dict = Counter(res)\n",
        "  print(dict)\n",
        "  print(sum(res)/len(res)) #get an average of all values(directions) in the res list \n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 408, 1: 266, 0: 88, 2: 48})\n",
            "1.9580246913580246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hkt31RHIIYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[0.61,0.766,0.84,0.75,0.71,0.21,0.49,0.26,0.17,0.25,0.32,0.43,0.44,0.23,0.28,0.77,0.26,0.96,0.91,0.74,0.62,1,1.3]\n",
        "b=5\n",
        "a=0\n",
        "for i in x:\n",
        "  xnor=((b-a)*((i-min(x))/(max(x)-min(x))))+a\n",
        "  print(int(xnor))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}